{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224c9562",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ§¾ Legal Document Similarity Checker (EURI + FAISS/Qdrant)\n",
    "Pipeline: Generate dataset â†’ Load â†’ Clean â†’ Chunk â†’ Embed (EURI) â†’ Store (FAISS/Qdrant) â†’ Retrieve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8f9aa",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup\n",
    "Uncomment to install deps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e7984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting euriai\n",
      "  Downloading euriai-1.0.32-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: qdrant-client in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (1.15.1)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from euriai) (2.32.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from euriai) (6.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from qdrant-client) (1.74.0)\n",
      "Collecting httpx>=0.20.0 (from httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from qdrant-client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from qdrant-client) (6.32.0)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from qdrant-client) (2.11.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from qdrant-client) (2.5.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from portalocker<4.0,>=2.7.0->qdrant-client) (311)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\papam\\anaconda3\\envs\\vectordb\\lib\\site-packages (from requests->euriai) (3.4.3)\n",
      "Downloading euriai-1.0.32-py3-none-any.whl (53 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: python-dotenv, h11, httpcore, euriai, httpx\n",
      "\n",
      "  Attempting uninstall: h11\n",
      "\n",
      "    Found existing installation: h11 0.9.0\n",
      "\n",
      "    Uninstalling h11-0.9.0:\n",
      "\n",
      "      Successfully uninstalled h11-0.9.0\n",
      "\n",
      "  Attempting uninstall: httpcore\n",
      "\n",
      "    Found existing installation: httpcore 0.9.1\n",
      "\n",
      "   ---------------- ----------------------- 2/5 [httpcore]\n",
      "    Uninstalling httpcore-0.9.1:\n",
      "   ---------------- ----------------------- 2/5 [httpcore]\n",
      "      Successfully uninstalled httpcore-0.9.1\n",
      "   ---------------- ----------------------- 2/5 [httpcore]\n",
      "   ---------------- ----------------------- 2/5 [httpcore]\n",
      "   ------------------------ --------------- 3/5 [euriai]\n",
      "  Attempting uninstall: httpx\n",
      "   ------------------------ --------------- 3/5 [euriai]\n",
      "    Found existing installation: httpx 0.13.3\n",
      "   ------------------------ --------------- 3/5 [euriai]\n",
      "    Uninstalling httpx-0.13.3:\n",
      "   ------------------------ --------------- 3/5 [euriai]\n",
      "      Successfully uninstalled httpx-0.13.3\n",
      "   ------------------------ --------------- 3/5 [euriai]\n",
      "   -------------------------------- ------- 4/5 [httpx]\n",
      "   ---------------------------------------- 5/5 [httpx]\n",
      "\n",
      "Successfully installed euriai-1.0.32 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 python-dotenv-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "googletrans 4.0.0rc1 requires httpx==0.13.3, but you have httpx 0.28.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%bash\n",
    "!pip install -U euriai faiss-cpu qdrant-client python-dotenv numpy pandas tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55827a4b",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Configuration\n",
    "Set your `EURI_API_KEY` via env or `.env`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f9905c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config OK. FAISS: True Qdrant: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "EURI_API_KEY = os.getenv(\"EURI_API_KEY\", \"{EURI_API_KEY}\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_COLLECTION = os.getenv(\"QDRANT_COLLECTION\", \"legal_clauses\")\n",
    "\n",
    "USE_FAISS = True\n",
    "USE_QDRANT = False\n",
    "\n",
    "assert EURI_API_KEY and EURI_API_KEY != \"EURI_API_KEY\", \"Please set EURI_API_KEY\"\n",
    "print(\"Config OK. FAISS:\", USE_FAISS, \"Qdrant:\", USE_QDRANT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887df83c",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Generate mock dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb8e1abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 5 docs to D:\\Dou\\EURON\\Gen AI Certification Bootcamp\\assign_vectordb\\data\\legal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "DATA_DIR = Path(\"data/legal\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "docs = {\n",
    "    \"SaaS_Master_Subscription_Agreement.txt\": '''\n",
    "    1. Definitions\n",
    "    \"Service\" means the subscription-based software service provided by Vendor.\n",
    "    \"Customer Data\" refers to information submitted by Customer to the Service.\n",
    "\n",
    "    2. Term and Termination\n",
    "    This Agreement commences on the Effective Date and continues for the Initial Term of twelve (12) months.\n",
    "    Either party may terminate this Agreement for material breach if such breach remains uncured for thirty (30) days after written notice.\n",
    "    Upon termination, Customer's access to the Service shall cease, except solely for limited export of Customer Data for thirty (30) days.\n",
    "\n",
    "    3. Confidentiality\n",
    "    Each party agrees to maintain the confidentiality of the other party's Confidential Information and use it only as permitted under this Agreement.\n",
    "    Confidential Information does not include information that becomes public without breach, or is independently developed without use of Confidential Information.\n",
    "\n",
    "    4. Payment Terms\n",
    "    Fees are due within thirty (30) days of invoice date. Late payments may accrue interest at 1.5% per month or the maximum allowed by law.\n",
    "\n",
    "    5. Limitation of Liability\n",
    "    Neither party shall be liable for indirect, incidental, special, consequential, or punitive damages.\n",
    "    ''',\n",
    "    \"Employment_Agreement.txt\": '''\n",
    "    1. Employment and Duties\n",
    "    Employee shall perform the duties described in the attached Job Description to the best of Employee's ability.\n",
    "\n",
    "    2. Compensation and Benefits\n",
    "    Employer shall pay Employee the salary stated in Exhibit A in accordance with Employer's standard payroll practices.\n",
    "\n",
    "    3. Confidentiality and IP\n",
    "    Employee agrees to keep Employer's trade secrets confidential and to assign any inventions developed in the scope of employment to Employer.\n",
    "\n",
    "    4. Termination\n",
    "    Employer may terminate employment for Cause immediately upon notice.\n",
    "    Employee may resign with two weeks' notice.\n",
    "    In either case, all Employer property must be returned upon termination.\n",
    "\n",
    "    5. Governing Law\n",
    "    This Agreement is governed by the laws of the State of New York, without regard to conflict of law principles.\n",
    "    ''',\n",
    "    \"Privacy_Policy.txt\": '''\n",
    "    1. Introduction\n",
    "    We value your privacy and explain here how we collect, use, and disclose personal data.\n",
    "\n",
    "    2. Data Collection\n",
    "    We collect information you provide directly and information collected automatically via cookies and similar technologies.\n",
    "\n",
    "    3. Data Use\n",
    "    We use your data to provide and improve services, personalize content, and comply with legal obligations.\n",
    "\n",
    "    4. Data Retention & Deletion\n",
    "    We retain personal data for as long as necessary for the purposes described. You may request deletion subject to legal requirements.\n",
    "\n",
    "    5. Contact\n",
    "    You can contact our Data Protection Officer at dpo@example.com.\n",
    "    ''',\n",
    "    \"Vendor_Service_Agreement.txt\": '''\n",
    "    1. Scope of Services\n",
    "    Vendor shall provide the services outlined in Statement of Work(s).\n",
    "\n",
    "    2. Termination for Convenience\n",
    "    Client may terminate this Agreement for convenience upon thirty (30) days' prior written notice.\n",
    "    Upon such termination, Vendor shall be paid for services performed up to the date of termination.\n",
    "\n",
    "    3. Confidentiality\n",
    "    Vendor shall not disclose Client's Confidential Information except as necessary to perform services.\n",
    "\n",
    "    4. Indemnification\n",
    "    Vendor shall indemnify and hold Client harmless from third-party claims arising out of Vendor's negligence or willful misconduct.\n",
    "    ''',\n",
    "    \"Partner_Reseller_Agreement.txt\": '''\n",
    "    1. Appointment\n",
    "    Company appoints Reseller as a non-exclusive reseller of the Products in the Territory.\n",
    "\n",
    "    2. Orders and Payment\n",
    "    All orders are subject to acceptance by Company. Payment is due net fifteen (15) days from invoice.\n",
    "    Late payments may incur finance charges.\n",
    "\n",
    "    3. Term and Termination\n",
    "    This Agreement shall remain in effect for one (1) year and automatically renew unless either party gives notice of non-renewal.\n",
    "    Either party may terminate for material breach not cured within fifteen (15) days after written notice.\n",
    "\n",
    "    4. Governing Law\n",
    "    This Agreement will be governed by the laws of England and Wales.\n",
    "    '''\n",
    "}\n",
    "\n",
    "for filename, content in docs.items():\n",
    "    (DATA_DIR / filename).write_text(textwrap.dedent(content).strip(), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Wrote\", len(docs), \"docs to\", DATA_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723fa36a",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Load, clean, chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da97885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re, glob\n",
    "from typing import List, Dict\n",
    "\n",
    "def load_documents(path=\"data/legal/*.txt\"):\n",
    "    recs = []\n",
    "    for fp in glob.glob(path):\n",
    "        with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "            recs.append({\"path\": fp, \"text\": f.read()})\n",
    "    return recs\n",
    "\n",
    "def clean_text(t: str) -> str:\n",
    "    t = t.replace(\"\\r\", \"\\n\")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    t = re.sub(r\"(?m)^\\s*\\d+\\.\\s*\", \"\", t)\n",
    "    return t.strip()\n",
    "\n",
    "def split_on_blocks(text: str) -> List[str]:\n",
    "    return [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
    "\n",
    "def window_chunks(blocks: List[str], target_chars=900, overlap_chars=150) -> List[str]:\n",
    "    chunks, buf = [], \"\"\n",
    "    for b in blocks:\n",
    "        if not buf:\n",
    "            buf = b\n",
    "        elif len(buf) + 2 + len(b) <= target_chars:\n",
    "            buf = buf + \"\\\\n\\\\n\" + b\n",
    "        else:\n",
    "            chunks.append(buf.strip())\n",
    "            buf = (buf[-overlap_chars:] + \"\\\\n\\\\n\" + b) if overlap_chars and len(buf) > overlap_chars else b\n",
    "    if buf.strip():\n",
    "        chunks.append(buf.strip())\n",
    "    return chunks\n",
    "\n",
    "def chunk_document(doc: Dict) -> List[Dict]:\n",
    "    blocks = split_on_blocks(clean_text(doc[\"text\"]))\n",
    "    chunks = window_chunks(blocks, target_chars=900, overlap_chars=150)\n",
    "    return [{\n",
    "        \"doc_path\": doc[\"path\"],\n",
    "        \"chunk_id\": f\"{os.path.basename(doc['path'])}::chunk_{i}\",\n",
    "        \"text\": ch\n",
    "    } for i, ch in enumerate(chunks)]\n",
    "\n",
    "docs_raw = load_documents()\n",
    "all_chunks = []\n",
    "for d in docs_raw:\n",
    "    all_chunks.extend(chunk_document(d))\n",
    "\n",
    "print(\"Total chunks:\", len(all_chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f154a92",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Embed with **EURI**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f03478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EURI embedding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:17<00:00,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (5, 1536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from euriai.embedding import EuriaiEmbeddingClient\n",
    "\n",
    "embed_client = EuriaiEmbeddingClient(api_key=EURI_API_KEY)\n",
    "\n",
    "def embed_texts(texts):\n",
    "    vecs = []\n",
    "    for t in tqdm(texts, desc=\"EURI embedding\"):\n",
    "        v = np.array(embed_client.embed(t), dtype=np.float32)\n",
    "        v = v / (np.linalg.norm(v) + 1e-12)  # L2 normalize\n",
    "        vecs.append(v)\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "texts = [c[\"text\"] for c in all_chunks]\n",
    "embeddings = embed_texts(texts)\n",
    "dim = embeddings.shape[1]\n",
    "print(\"Embeddings:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97631174",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Store in FAISS (local) or Qdrant (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6622e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index size: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "faiss = None\n",
    "if USE_FAISS:\n",
    "    try:\n",
    "        import faiss\n",
    "    except Exception as e:\n",
    "        print(\"FAISS not available, will use NumPy fallback.\", e)\n",
    "\n",
    "if USE_FAISS and 'faiss' in globals() and faiss is not None:\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(embeddings)\n",
    "    print(\"FAISS index size:\", index.ntotal)\n",
    "else:\n",
    "    index = None\n",
    "    print(\"Using NumPy fallback.\")\n",
    "\n",
    "id_to_meta = {i: all_chunks[i] for i in range(len(all_chunks))}\n",
    "\n",
    "if USE_QDRANT:\n",
    "    from qdrant_client import QdrantClient\n",
    "    from qdrant_client.http import models as qmodels\n",
    "    qclient = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "    qclient.recreate_collection(\n",
    "        collection_name=QDRANT_COLLECTION,\n",
    "        vectors_config=qmodels.VectorParams(size=dim, distance=qmodels.Distance.COSINE),\n",
    "    )\n",
    "    qclient.upsert(\n",
    "        collection_name=QDRANT_COLLECTION,\n",
    "        points=qmodels.Batch(\n",
    "            ids=list(range(len(embeddings))),\n",
    "            vectors=embeddings.tolist(),\n",
    "            payloads=[{\n",
    "                \"doc_path\": m[\"doc_path\"],\n",
    "                \"chunk_id\": m[\"chunk_id\"],\n",
    "                \"text\": m[\"text\"],\n",
    "            } for m in all_chunks],\n",
    "        ),\n",
    "        wait=True,\n",
    "    )\n",
    "    print(\"Pushed to Qdrant:\", QDRANT_COLLECTION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78285545",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Retrieval helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4392e220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def search_local(query: str, top_k=5):\n",
    "    qv = np.array(embed_client.embed(query), dtype=np.float32)\n",
    "    qv = qv / (np.linalg.norm(qv) + 1e-12)\n",
    "\n",
    "    if index is not None:\n",
    "        D, I = index.search(qv.reshape(1, -1), top_k)\n",
    "        scores, ids = D[0].tolist(), I[0].tolist()\n",
    "    else:\n",
    "        sims = embeddings @ qv\n",
    "        ids = sims.argsort()[-top_k:][::-1].tolist()\n",
    "        scores = sims[ids].tolist()\n",
    "\n",
    "    results = []\n",
    "    for i, s in zip(ids, scores):\n",
    "        m = id_to_meta[i]\n",
    "        results.append({\n",
    "            \"score\": float(s),\n",
    "            \"doc\": os.path.basename(m[\"doc_path\"]),\n",
    "            \"chunk_id\": m[\"chunk_id\"],\n",
    "            \"text\": m[\"text\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def pretty(results):\n",
    "    for r in results:\n",
    "        print(f\"[{r['score']:.3f}] {r['doc']} :: {r['chunk_id']}\")\n",
    "        print(r['text'])\n",
    "        print(\"-\"*80)\n",
    "\n",
    "print(\"Search ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315c422",
   "metadata": {},
   "source": [
    "\n",
    "### Try a clause query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9c6096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.377] Employment_Agreement.txt :: Employment_Agreement.txt::chunk_0\n",
      "Employment and Duties\n",
      "Employee shall perform the duties described in the attached Job Description to the best of Employee's ability.\n",
      "Compensation and Benefits\n",
      "Employer shall pay Employee the salary stated in Exhibit A in accordance with Employer's standard payroll practices.\n",
      "Confidentiality and IP\n",
      "Employee agrees to keep Employer's trade secrets confidential and to assign any inventions developed in the scope of employment to Employer.\n",
      "Termination\n",
      "Employer may terminate employment for Cause immediately upon notice.\n",
      "Employee may resign with two weeks' notice.\n",
      "In either case, all Employer property must be returned upon termination.\n",
      "Governing Law\n",
      "This Agreement is governed by the laws of the State of New York, without regard to conflict of law principles.\n",
      "--------------------------------------------------------------------------------\n",
      "[0.358] Vendor_Service_Agreement.txt :: Vendor_Service_Agreement.txt::chunk_0\n",
      "Scope of Services\n",
      "Vendor shall provide the services outlined in Statement of Work(s).\n",
      "Termination for Convenience\n",
      "Client may terminate this Agreement for convenience upon thirty (30) days' prior written notice.\n",
      "Upon such termination, Vendor shall be paid for services performed up to the date of termination.\n",
      "Confidentiality\n",
      "Vendor shall not disclose Client's Confidential Information except as necessary to perform services.\n",
      "Indemnification\n",
      "Vendor shall indemnify and hold Client harmless from third-party claims arising out of Vendor's negligence or willful misconduct.\n",
      "--------------------------------------------------------------------------------\n",
      "[0.352] Partner_Reseller_Agreement.txt :: Partner_Reseller_Agreement.txt::chunk_0\n",
      "Appointment\n",
      "Company appoints Reseller as a non-exclusive reseller of the Products in the Territory.\n",
      "Orders and Payment\n",
      "All orders are subject to acceptance by Company. Payment is due net fifteen (15) days from invoice.\n",
      "Late payments may incur finance charges.\n",
      "Term and Termination\n",
      "This Agreement shall remain in effect for one (1) year and automatically renew unless either party gives notice of non-renewal.\n",
      "Either party may terminate for material breach not cured within fifteen (15) days after written notice.\n",
      "Governing Law\n",
      "This Agreement will be governed by the laws of England and Wales.\n",
      "--------------------------------------------------------------------------------\n",
      "[0.351] SaaS_Master_Subscription_Agreement.txt :: SaaS_Master_Subscription_Agreement.txt::chunk_0\n",
      "Definitions\n",
      "\"Service\" means the subscription-based software service provided by Vendor.\n",
      "\"Customer Data\" refers to information submitted by Customer to the Service.\n",
      "Term and Termination\n",
      "This Agreement commences on the Effective Date and continues for the Initial Term of twelve (12) months.\n",
      "Either party may terminate this Agreement for material breach if such breach remains uncured for thirty (30) days after written notice.\n",
      "Upon termination, Customer's access to the Service shall cease, except solely for limited export of Customer Data for thirty (30) days.\n",
      "Confidentiality\n",
      "Each party agrees to maintain the confidentiality of the other party's Confidential Information and use it only as permitted under this Agreement.\n",
      "Confidential Information does not include information that becomes public without breach, or is independently developed without use of Confidential Information.\n",
      "Payment Terms\n",
      "Fees are due within thirty (30) days of invoice date. Late payments may accrue interest at 1.5% per month or the maximum allowed by law.\n",
      "Limitation of Liability\n",
      "Neither party shall be liable for indirect, incidental, special, consequential, or punitive damages.\n",
      "--------------------------------------------------------------------------------\n",
      "[0.166] Privacy_Policy.txt :: Privacy_Policy.txt::chunk_0\n",
      "Introduction\n",
      "We value your privacy and explain here how we collect, use, and disclose personal data.\n",
      "Data Collection\n",
      "We collect information you provide directly and information collected automatically via cookies and similar technologies.\n",
      "Data Use\n",
      "We use your data to provide and improve services, personalize content, and comply with legal obligations.\n",
      "Data Retention & Deletion\n",
      "We retain personal data for as long as necessary for the purposes described. You may request deletion subject to legal requirements.\n",
      "Contact\n",
      "You can contact our Data Protection Officer at dpo@example.com.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = search_local(\"termination conditions\", top_k=5)\n",
    "pretty(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb5bf5",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f27f930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>len</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Employment_Agreement.txt</td>\n",
       "      <td>Employment_Agreement.txt::chunk_0</td>\n",
       "      <td>762</td>\n",
       "      <td>Employment and Duties\\nEmployee shall perform ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Partner_Reseller_Agreement.txt</td>\n",
       "      <td>Partner_Reseller_Agreement.txt::chunk_0</td>\n",
       "      <td>592</td>\n",
       "      <td>Appointment\\nCompany appoints Reseller as a no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Privacy_Policy.txt</td>\n",
       "      <td>Privacy_Policy.txt::chunk_0</td>\n",
       "      <td>584</td>\n",
       "      <td>Introduction\\nWe value your privacy and explai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SaaS_Master_Subscription_Agreement.txt</td>\n",
       "      <td>SaaS_Master_Subscription_Agreement.txt::chunk_0</td>\n",
       "      <td>1161</td>\n",
       "      <td>Definitions\\n\"Service\" means the subscription-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Vendor_Service_Agreement.txt</td>\n",
       "      <td>Vendor_Service_Agreement.txt::chunk_0</td>\n",
       "      <td>571</td>\n",
       "      <td>Scope of Services\\nVendor shall provide the se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                     doc  \\\n",
       "0   0                Employment_Agreement.txt   \n",
       "1   1          Partner_Reseller_Agreement.txt   \n",
       "2   2                      Privacy_Policy.txt   \n",
       "3   3  SaaS_Master_Subscription_Agreement.txt   \n",
       "4   4            Vendor_Service_Agreement.txt   \n",
       "\n",
       "                                          chunk_id   len  \\\n",
       "0                Employment_Agreement.txt::chunk_0   762   \n",
       "1          Partner_Reseller_Agreement.txt::chunk_0   592   \n",
       "2                      Privacy_Policy.txt::chunk_0   584   \n",
       "3  SaaS_Master_Subscription_Agreement.txt::chunk_0  1161   \n",
       "4            Vendor_Service_Agreement.txt::chunk_0   571   \n",
       "\n",
       "                                             preview  \n",
       "0  Employment and Duties\\nEmployee shall perform ...  \n",
       "1  Appointment\\nCompany appoints Reseller as a no...  \n",
       "2  Introduction\\nWe value your privacy and explai...  \n",
       "3  Definitions\\n\"Service\" means the subscription-...  \n",
       "4  Scope of Services\\nVendor shall provide the se...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": i,\n",
    "        \"doc\": os.path.basename(m[\"doc_path\"]),\n",
    "        \"chunk_id\": m[\"chunk_id\"],\n",
    "        \"len\": len(m[\"text\"]),\n",
    "        \"preview\": m[\"text\"][:120].replace(\"\\\\n\",\" \")\n",
    "    } for i, m in id_to_meta.items()\n",
    "]).sort_values([\"doc\",\"id\"]).reset_index(drop=True)\n",
    "df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
