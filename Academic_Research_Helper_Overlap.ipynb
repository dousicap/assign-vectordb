{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8557aa",
   "metadata": {},
   "source": [
    "# Academic Research Helper avec overlap dans le chunking\n",
    "\n",
    "Objectif: ing√©rer des abstracts acad√©miques synth√©tiques, les d√©couper en morceaux avec overlap, les encoder (via EURI si une cl√© est fournie, fallback local sinon), les stocker dans Qdrant et permettre une recherche s√©mantique pour des requ√™tes comme ¬´ transformers in computer vision ¬ª. Le chunking inclut d√©sormais un overlap entre chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89a8d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "# Configuration\n",
    "VECTOR_SIZE = 128\n",
    "CHUNK_MAX_CHARS = 600\n",
    "CHUNK_OVERLAP_CHARS = 100  # overlap between consecutive chunks (in characters)\n",
    "COLLECTION_NAME = \"dou_academic_papers\"\n",
    "\n",
    "# Qdrant host/port (override via environment if needed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34ca2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n: int = 6) -> List[Dict[str, Any]]:\n",
    "    \"\"\"G√©n√®re un petit jeu de donn√©es synth√©tiques de papiers (id, title, abstract).\"\"\"\n",
    "    base_papers = [\n",
    "        {\"id\": \"P1\", \"title\": \"Transformers in Computer Vision: A Survey\",\n",
    "         \"abstract\": \"The transformer architecture has emerged as a powerful model for sequence modeling. This paper surveys transformer-based models in computer vision, including ViT, DeiT, and data-efficient variants. We discuss architectures, training regimes, and evaluation benchmarks.\"},\n",
    "        {\"id\": \"P2\", \"title\": \"Vision Transformers for Image Recognition\",\n",
    "         \"abstract\": \"We examine Vision Transformers (ViT) architectures, patch embeddings, and how self-attention captures long-range dependencies in images. We compare with CNN-based baselines and discuss efficiency and scalability.\"},\n",
    "        {\"id\": \"P3\", \"title\": \"Self-Attention Mechanisms in Vision Tasks\",\n",
    "         \"abstract\": \"Self-attention modules and their variants are applied to object detection, segmentation, and action recognition. We analyze computational trade-offs and show improvements on common benchmarks.\"},\n",
    "        {\"id\": \"P4\", \"title\": \"Transformers in Object Detection\",\n",
    "         \"abstract\": \"Transformers extend detection pipelines with query-based decoding and cross-attention. This paper surveys DETR-like models and improvements such as Deformable DETR and query-based attention.\"},\n",
    "        {\"id\": \"P5\", \"title\": \"Efficient Transformers for Vision\",\n",
    "         \"abstract\": \"We discuss efficiency techniques in transformers for vision, including sparse attention, kernel-based methods, and distillation strategies to reduce compute and memory footprints.\"},\n",
    "        {\"id\": \"P6\", \"title\": \"Multimodal Transformers for Vision-Language\",\n",
    "         \"abstract\": \"Extending transformers to vision-language tasks, we review approaches like CLIP and ALIGN, focusing on alignment between text and image representations and zero-shot capabilities.\"},\n",
    "    ]\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        p = base_papers[i % len(base_papers)].copy()\n",
    "        p[\"id\"] = f\"{p['id']}_{i}\"\n",
    "        out.append(p)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfcdef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ab17c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars: int = CHUNK_MAX_CHARS, overlap_chars: int = CHUNK_OVERLAP_CHARS) -> List[str]:\n",
    "    \"\"\"D√©coupe le texte en chunks avec overlap entre chunks.\n",
    "\n",
    "    Param√®tres:\n",
    "      max_chars: longueur maximale d'un chunk en caract√®res.\n",
    "      overlap_chars: nombre de caract√®res qui se chevauchent entre chunks cons√©cutifs.\n",
    "    \"\"\"\n",
    "    if max_chars <= 0:\n",
    "        return [text]\n",
    "    chunks: List[str] = []\n",
    "    if not text:\n",
    "        return chunks\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "    while i < n:\n",
    "        end = min(i + max_chars, n)\n",
    "        chunk = text[i:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        if end >= n:\n",
    "            break\n",
    "        # Avancer en laissant un overlap de chars entre les chunks\n",
    "        i = max(0, end - overlap_chars)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75359a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Embedding function: utilise l‚ÄôAPI EURI si cl√© pr√©sente; sinon, fallback local d√©terministe.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"EURI_API_KEY\")\n",
    "    endpoint = os.getenv(\"EURI_EMBEDDING_ENDPOINT\", \"https://api.euri.ai/v1/embed\")\n",
    "\n",
    "    if api_key:\n",
    "        try:\n",
    "            headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "            payload = {\"text\": text}\n",
    "            resp = requests.post(endpoint, json=payload, headers=headers, timeout=60)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            embedding = None\n",
    "            if isinstance(data, dict):\n",
    "                embedding = data.get(\"embedding\") or data.get(\"vector\") or data.get(\"embeddings\")\n",
    "            if isinstance(embedding, list):\n",
    "                return embedding\n",
    "        except Exception as e:\n",
    "            print(f\"[EURI] Embedding API failed: {e}\")\n",
    "\n",
    "    # Fallback deterministe (128-dim)\n",
    "    dim = VECTOR_SIZE\n",
    "    vec = [0.0] * dim\n",
    "    for idx, ch in enumerate(text):\n",
    "        vec[idx % dim] += (ord(ch) / 255.0)\n",
    "    norm = sum(v * v for v in vec) ** 0.5\n",
    "    if norm > 0:\n",
    "        vec = [v / norm for v in vec]\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2584412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_collection(client: QdrantClient, name: str) -> None:\n",
    "    try:\n",
    "        client.recreate_collection(\n",
    "            collection_name=name,\n",
    "            vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)\n",
    "        )\n",
    "        print(f\"Collection '{name}' recreated.\")\n",
    "    except Exception:\n",
    "        print(f\"Collection '{name}' already exists or could not be recreated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b058457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_store_dataset(papers, client, collection_name):\n",
    "    points = []\n",
    "    point_ids = []\n",
    "\n",
    "    for paper in papers:\n",
    "        # üëá fallback: essaie \"text\", sinon \"abstract\", sinon \"content\"\n",
    "        text = paper.get(\"text\") or paper.get(\"abstract\") or paper.get(\"content\")\n",
    "        if not text:\n",
    "            continue  # skip si aucun texte\n",
    "\n",
    "        chunks = chunk_text(text)\n",
    "        embeddings = generate_embeddings(chunks)\n",
    "\n",
    "        for chunk, vector in zip(chunks, embeddings):\n",
    "            pid = str(uuid.uuid4())\n",
    "            points.append(\n",
    "                PointStruct(\n",
    "                    id=pid,\n",
    "                    vector=vector,\n",
    "                    payload={\n",
    "                        \"title\": paper.get(\"title\", \"\"),\n",
    "                        \"text_snippet\": chunk,\n",
    "                        \"lang\": paper.get(\"lang\", \"en\")\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            point_ids.append(pid)\n",
    "\n",
    "    if points:\n",
    "        client.upsert(collection_name=collection_name, points=points)\n",
    "    return point_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fc133d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_payload_score(res: Any) -> Tuple[Dict[str, Any], float]:\n",
    "    payload = getattr(res, \"payload\", None)\n",
    "    score = getattr(res, \"score\", None)\n",
    "    if payload is None and isinstance(res, dict):\n",
    "        payload = res.get(\"payload\", {})\n",
    "        score = res.get(\"score\", 0.0)\n",
    "    return payload if payload is not None else {}, float(score if score is not None else 0.0)\n",
    "\n",
    "def retrieve_papers(query: str, client: QdrantClient, collection_name: str = COLLECTION_NAME, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "    vec = generate_embeddings(query)\n",
    "    results = client.search(collection_name=collection_name, query_vector=vec, top=top_k, with_payload=True)\n",
    "    hits: List[Dict[str, Any]] = []\n",
    "    for r in results:\n",
    "        payload, score = _extract_payload_score(r)\n",
    "        title = payload.get(\"title\")\n",
    "        paper_id = payload.get(\"paper_id\")\n",
    "        chunk_id = payload.get(\"chunk_id\")\n",
    "        text = payload.get(\"text\", \"\")\n",
    "        hits.append({\n",
    "            \"score\": score,\n",
    "            \"paper_id\": paper_id,\n",
    "            \"title\": title,\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"text_snippet\": text[:200] + (\"...\" if len(text) > 200 else \"\")\n",
    "        })\n",
    "    return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\papam\\AppData\\Local\\Temp\\ipykernel_276\\3355747868.py:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'dou_academic_papers' recreated.\n",
      "Ingesting papers into Qdrant...\n",
      "[EURI] Embedding API failed: HTTPSConnectionPool(host='api.euri.ai', port=443): Max retries exceeded with url: /v1/embed (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001D90EC090C0>: Failed to resolve 'api.euri.ai' (Name or service not known: api.euri.ai using 1 resolver(s))\"))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ord() expected a character, but string of length 268 found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Snippet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_snippet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Execute the demo when running this notebook cell\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mrun_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 17\u001b[0m, in \u001b[0;36mrun_demo\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2) Build and store (chunk + embed + store)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIngesting papers into Qdrant...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m stored_ids \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_and_store_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpapers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqdrant_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOLLECTION_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStored \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(stored_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chunks across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(papers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m papers.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 3) Semantic query example\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 12\u001b[0m, in \u001b[0;36mbuild_and_store_dataset\u001b[1;34m(papers, client, collection_name)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# skip si aucun texte\u001b[39;00m\n\u001b[0;32m     11\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunk_text(text)\n\u001b[1;32m---> 12\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk, vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chunks, embeddings):\n\u001b[0;32m     15\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n",
      "Cell \u001b[1;32mIn[29], line 27\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     25\u001b[0m vec \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m dim\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(text):\n\u001b[1;32m---> 27\u001b[0m     vec[idx \u001b[38;5;241m%\u001b[39m dim] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m)\n\u001b[0;32m     28\u001b[0m norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(v \u001b[38;5;241m*\u001b[39m v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vec) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: ord() expected a character, but string of length 268 found"
     ]
    }
   ],
   "source": [
    "def run_demo():\n",
    "    # Init Qdrant client\n",
    "    \n",
    "    qdrant_client = QdrantClient(\n",
    "                                url=\"{QDRANT_URL}\", \n",
    "                                api_key=\"{QDRANT_API_KEY}\"\n",
    "                                )\n",
    "\n",
    "    # Ensure collection exists/established\n",
    "    ensure_collection(qdrant_client, COLLECTION_NAME)\n",
    "\n",
    "    # 1) Generate dataset\n",
    "    papers = generate_dataset(n=6)\n",
    "\n",
    "    # 2) Build and store (chunk + embed + store)\n",
    "    print(\"Ingesting papers into Qdrant...\")\n",
    "    stored_ids = build_and_store_dataset(papers, qdrant_client, COLLECTION_NAME)\n",
    "    print(f\"Stored {len(stored_ids)} chunks across {len(papers)} papers.\")\n",
    "\n",
    "    # 3) Semantic query example\n",
    "    query = \"transformers in computer vision\"\n",
    "    print(f\"Query: {query}\")\n",
    "    results = retrieve_papers(query, qdrant_client, COLLECTION_NAME, top_k=5)\n",
    "    print(\"Top results:\")\n",
    "    for r in results:\n",
    "        print(f\"- Paper ID: {r['paper_id']}, Title: {r['title']}, Score: {r['score']:.4f}\")\n",
    "        print(f\"  Snippet: {r['text_snippet']}\")\n",
    "\n",
    "# Execute the demo when running this notebook cell\n",
    "run_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
